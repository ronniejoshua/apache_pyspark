{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder\n",
    "                  .appName(\"Spark SQL Query Dataframes\")\n",
    "                  .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{data_path}/utilization.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = (spark.read\n",
    "        .format(\"json\")\n",
    "        .load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.64|03/28/2019 08:16:52|       0.38|      122|           72|\n",
      "|           0.66|03/28/2019 08:21:52|       0.22|      122|           69|\n",
      "|           0.55|03/28/2019 08:26:52|       0.52|      122|           80|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cpu_utilization: double (nullable = true)\n",
      " |-- event_datetime: string (nullable = true)\n",
      " |-- free_memory: double (nullable = true)\n",
      " |-- server_id: long (nullable = true)\n",
      " |-- session_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_sql = spark.sql(\"SELECT * FROM utilization LIMIT 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.64|03/28/2019 08:16:52|       0.38|      122|           72|\n",
      "|           0.66|03/28/2019 08:21:52|       0.22|      122|           69|\n",
      "|           0.55|03/28/2019 08:26:52|       0.52|      122|           80|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_sql.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      122|           72|\n",
      "|      122|           69|\n",
      "|      122|           80|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"SELECT server_id, session_count FROM utilization LIMIT 3\")\n",
    "sdf_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|sid| sc|\n",
      "+---+---+\n",
      "|122| 72|\n",
      "|122| 69|\n",
      "|122| 80|\n",
      "+---+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"SELECT server_id as sid, session_count as sc FROM utilization\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.66|03/05/2019 08:06:48|       0.31|      120|           54|\n",
      "|           0.58|03/05/2019 08:11:48|       0.38|      120|           64|\n",
      "|           0.55|03/05/2019 08:16:48|       0.61|      120|           54|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"SELECT * FROM utilization WHERE server_id = 120\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      122|           72|\n",
      "|      122|           80|\n",
      "|      122|           77|\n",
      "+---------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"SELECT server_id, session_count FROM utilization WHERE session_count > 70\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      120|           80|\n",
      "|      120|           71|\n",
      "|      120|           73|\n",
      "+---------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"SELECT server_id, session_count FROM utilization WHERE session_count > 70 AND server_id = 120\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|server_id|session_count|\n",
      "+---------+-------------+\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "|      120|           80|\n",
      "+---------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"\"\"\n",
    "                   SELECT server_id, session_count\n",
    "                   FROM utilization\n",
    "                   WHERE session_count > 70 AND server_id = 120\n",
    "                   ORDER BY session_count DESC\n",
    "                 \"\"\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  500000|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"SELECT count(*) FROM utilization\")\n",
    "sdf_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  239659|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"SELECT count(*) \\\n",
    "                    FROM utilization \\\n",
    "                    WHERE session_count > 70\")\n",
    "sdf_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      112|    7425|\n",
      "|      113|    9418|\n",
      "|      130|    2891|\n",
      "+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"\"\"SELECT server_id, count(*)\n",
    "                    FROM utilization\n",
    "                    WHERE session_count > 70\n",
    "                    GROUP BY server_id\"\"\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|server_id|count(1)|\n",
      "+---------+--------+\n",
      "|      101|    9808|\n",
      "|      113|    9418|\n",
      "|      145|    9304|\n",
      "+---------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"\"\"\n",
    "                    SELECT server_id, count(*)\n",
    "                    FROM utilization\n",
    "                    WHERE session_count > 70\n",
    "                    GROUP BY server_id\n",
    "                    ORDER BY count(*) DESC\n",
    "                    \"\"\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------+------------------+\n",
      "|server_id|min(session_count)|avg(session_count)|max(session_count)|\n",
      "+---------+------------------+------------------+------------------+\n",
      "|      101|                71| 87.66557911908646|               105|\n",
      "|      113|                71| 86.96262476109577|               103|\n",
      "|      145|                71| 86.97732158211522|               103|\n",
      "+---------+------------------+------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"\"\"\n",
    "                    SELECT server_id, min(session_count), avg(session_count), max(session_count)\n",
    "                    FROM utilization\n",
    "                    WHERE session_count > 70\n",
    "                    GROUP BY server_id\n",
    "                    ORDER BY count(*) DESC\n",
    "                \"\"\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------------------------+------------------+\n",
      "|server_id|min(session_count)|round(avg(session_count), 2)|max(session_count)|\n",
      "+---------+------------------+----------------------------+------------------+\n",
      "|      101|                71|                       87.67|               105|\n",
      "|      113|                71|                       86.96|               103|\n",
      "|      145|                71|                       86.98|               103|\n",
      "+---------+------------------+----------------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_sql = spark.sql(\"\"\"\n",
    "                    SELECT server_id, min(session_count), round(avg(session_count),2), max(session_count)\n",
    "                    FROM utilization\n",
    "                    WHERE session_count > 70\n",
    "                    GROUP BY server_id\n",
    "                    ORDER BY count(*) DESC\n",
    "                    \"\"\")\n",
    "sdf_sql.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{data_path}/utilization.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util = (spark.read\n",
    "               .format(\"json\")\n",
    "               .load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_util.createOrReplaceTempView(\"utilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|cpu_utilization|     event_datetime|free_memory|server_id|session_count|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "|           0.64|03/28/2019 08:16:52|       0.38|      122|           72|\n",
      "|           0.66|03/28/2019 08:21:52|       0.22|      122|           69|\n",
      "|           0.55|03/28/2019 08:26:52|       0.52|      122|           80|\n",
      "+---------------+-------------------+-----------+---------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{data_path}/server_name.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_server = (spark.read\n",
    "       .format(\"csv\")\n",
    "       .option(\"header\", \"true\")\n",
    "       .load(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|server_id|server_name|\n",
      "+---------+-----------+\n",
      "|      100| 100 Server|\n",
      "|      101| 101 Server|\n",
      "|      102| 102 Server|\n",
      "+---------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_server.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_server.createOrReplaceTempView(\"server_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|server_id|\n",
      "+---------+\n",
      "|      100|\n",
      "|      101|\n",
      "|      102|\n",
      "+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_count = spark.sql(\"SELECT DISTINCT server_id FROM utilization ORDER BY server_id\")\n",
    "df_count.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|min(server_id)|max(server_id)|\n",
      "+--------------+--------------+\n",
      "|           100|           149|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT min(server_id), max(server_id) FROM utilization\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|server_id|server_name|\n",
      "+---------+-----------+\n",
      "|      100| 100 Server|\n",
      "|      101| 101 Server|\n",
      "|      102| 102 Server|\n",
      "+---------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM server_name\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-------------+\n",
      "|server_id|server_name|session_count|\n",
      "+---------+-----------+-------------+\n",
      "|      122| 122 Server|           72|\n",
      "|      122| 122 Server|           69|\n",
      "|      122| 122 Server|           80|\n",
      "+---------+-----------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_join = spark.sql(\"\"\"\n",
    "                         SELECT u.server_id, sn.server_name, u.session_count\n",
    "                         FROM utilization AS u\n",
    "                         INNER JOIN server_name AS sn\n",
    "                         ON sn.server_id = u.server_id\n",
    "                    \"\"\")\n",
    "sdf_join.show(3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup = spark.sparkContext.parallelize([\n",
    "                             Row(server_name='101 Server', cpu_utilization=85, session_count=80),\n",
    "                             Row(server_name='101 Server', cpu_utilization=80, session_count=90),\n",
    "                             Row(server_name='102 Server', cpu_utilization=85, session_count=80),\n",
    "                             Row(server_name='102 Server', cpu_utilization=85, session_count=80)\n",
    "                        ]).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|server_name|cpu_utilization|session_count|\n",
      "+-----------+---------------+-------------+\n",
      "| 101 Server|             85|           80|\n",
      "| 101 Server|             80|           90|\n",
      "| 102 Server|             85|           80|\n",
      "| 102 Server|             85|           80|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|server_name|cpu_utilization|session_count|\n",
      "+-----------+---------------+-------------+\n",
      "| 101 Server|             85|           80|\n",
      "| 101 Server|             80|           90|\n",
      "| 102 Server|             85|           80|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup.drop_duplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|server_name|cpu_utilization|session_count|\n",
      "+-----------+---------------+-------------+\n",
      "| 102 Server|             85|           80|\n",
      "| 101 Server|             85|           80|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dup.drop_duplicates(['server_name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "|summary|    cpu_utilization|     event_datetime|        free_memory|         server_id|     session_count|\n",
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "|  count|             500000|             500000|             500000|            500000|            500000|\n",
      "|   mean| 0.6205177400000055|               null| 0.3791280999999993|             124.5|          69.59616|\n",
      "| stddev|0.15875173872912818|               null|0.15830931278376192|14.430884120553516|14.850676696352838|\n",
      "|    min|               0.22|03/05/2019 08:06:14|                0.0|               100|                32|\n",
      "|    max|                1.0|04/09/2019 01:22:46|               0.78|               149|               105|\n",
      "+-------+-------------------+-------------------+-------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|    cpu_utilization|        free_memory|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|             500000|             500000|\n",
      "|   mean| 0.6205177400000055| 0.3791280999999993|\n",
      "| stddev|0.15875173872912818|0.15830931278376192|\n",
      "|    min|               0.22|                0.0|\n",
      "|    max|                1.0|               0.78|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.describe('cpu_utilization','free_memory').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4704771573080726"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_util.stat.corr('cpu_utilization','free_memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------------+\n",
      "| server_id_freqItems|session_count_freqItems|\n",
      "+--------------------+-----------------------+\n",
      "|[137, 146, 101, 1...|   [92, 101, 83, 104...|\n",
      "+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_util.stat.freqItems(('server_id','session_count')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------------+\n",
      "|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "|                0.22|                 1.0|    0.15875173872912818|\n",
      "+--------------------+--------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization) FROM utilization').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|server_id|min(cpu_utilization)|max(cpu_utilization)|stddev(cpu_utilization)|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "|      112|                0.52|                0.92|    0.11528867845082576|\n",
      "|      113|                0.58|                0.98|    0.11544345150353694|\n",
      "|      130|                0.35|                0.75|    0.11568834774245991|\n",
      "+---------+--------------------+--------------------+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            SELECT server_id, min(cpu_utilization), max(cpu_utilization), stddev(cpu_utilization)\n",
    "            FROM utilization\n",
    "            GROUP BY server_id\n",
    "          \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|server_id|bucket|\n",
      "+---------+------+\n",
      "|      122|     6|\n",
      "|      122|     6|\n",
      "|      122|     5|\n",
      "+---------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT server_id, FLOOR(cpu_utilization*100/10) AS bucket FROM utilization').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_window = \"\"\"\n",
    "                SELECT \n",
    "                event_datetime, \n",
    "                server_id, \n",
    "                cpu_utilization,\n",
    "                avg(cpu_utilization) OVER (PARTITION BY server_id) AS avg_server_util\n",
    "                FROM utilization\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "|03/05/2019 08:06:34|      112|           0.71|0.7153870000000067|\n",
      "|03/05/2019 08:11:34|      112|           0.78|0.7153870000000067|\n",
      "|03/05/2019 08:16:34|      112|           0.87|0.7153870000000067|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(sql_window).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|   delta_server_util|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "|03/05/2019 08:06:34|      112|           0.71|0.7153870000000067|-0.00538700000000...|\n",
      "|03/05/2019 08:11:34|      112|           0.78|0.7153870000000067| 0.06461299999999337|\n",
      "|03/05/2019 08:16:34|      112|           0.87|0.7153870000000067| 0.15461299999999334|\n",
      "+-------------------+---------+---------------+------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_window = \"\"\"\n",
    "                SELECT \n",
    "                event_datetime, \n",
    "                server_id, \n",
    "                cpu_utilization,\n",
    "                avg(cpu_utilization) OVER (PARTITION BY server_id) AS avg_server_util,\n",
    "                cpu_utilization - avg(cpu_utilization) OVER (PARTITION BY server_id) AS delta_server_util\n",
    "                FROM utilization\n",
    "            \"\"\"\n",
    "spark.sql(sql_window).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------------+------------------+\n",
      "|     event_datetime|server_id|cpu_utilization|   avg_server_util|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "|03/05/2019 08:06:34|      112|           0.71|             0.745|\n",
      "|03/05/2019 08:11:34|      112|           0.78|0.7866666666666666|\n",
      "|03/05/2019 08:16:34|      112|           0.87|0.8233333333333333|\n",
      "+-------------------+---------+---------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_window = \"\"\"\n",
    "                SELECT \n",
    "                event_datetime, \n",
    "                server_id, \n",
    "                cpu_utilization,\n",
    "                avg(cpu_utilization) OVER(\n",
    "                                            PARTITION BY server_id \n",
    "                                            ORDER BY event_datetime\n",
    "                                            ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n",
    "                                        ) AS avg_server_util\n",
    "                FROM utilization\n",
    "            \"\"\"\n",
    "spark.sql(sql_window).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.sparkContext.parallelize(\n",
    "                            [Row(server_name='101 Server', cpu_utilization=85, session_count=80),\n",
    "                             Row(server_name='101 Server', cpu_utilization=80, session_count=90),\n",
    "                             Row(server_name='102 Server', cpu_utilization=85, session_count=40),\n",
    "                             Row(server_name='103 Server', cpu_utilization=70, session_count=80),\n",
    "                             Row(server_name='104 Server', cpu_utilization=60, session_count=80)]\n",
    "                            ).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+\n",
      "|server_name|cpu_utilization|session_count|\n",
      "+-----------+---------------+-------------+\n",
      "| 101 Server|             85|           80|\n",
      "| 101 Server|             80|           90|\n",
      "| 102 Server|             85|           40|\n",
      "| 103 Server|             70|           80|\n",
      "| 104 Server|             60|           80|\n",
      "+-----------+---------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_na = df.withColumn('na_col', lit(None).cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|  null|\n",
      "| 101 Server|             80|           90|  null|\n",
      "| 102 Server|             85|           40|  null|\n",
      "| 103 Server|             70|           80|  null|\n",
      "| 104 Server|             60|           80|  null|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_na.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_na.fillna('A').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_na.fillna('A').union(df_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "| 101 Server|             85|           80|  null|\n",
      "| 101 Server|             80|           90|  null|\n",
      "| 102 Server|             85|           40|  null|\n",
      "| 103 Server|             70|           80|  null|\n",
      "| 104 Server|             60|           80|  null|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.createOrReplaceTempView(\"na_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "| 101 Server|             85|           80|  null|\n",
      "| 101 Server|             80|           90|  null|\n",
      "| 102 Server|             85|           40|  null|\n",
      "| 103 Server|             70|           80|  null|\n",
      "| 104 Server|             60|           80|  null|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM na_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|  null|\n",
      "| 101 Server|             80|           90|  null|\n",
      "| 102 Server|             85|           40|  null|\n",
      "| 103 Server|             70|           80|  null|\n",
      "| 104 Server|             60|           80|  null|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM na_table WHERE na_col IS NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-------------+------+\n",
      "|server_name|cpu_utilization|session_count|na_col|\n",
      "+-----------+---------------+-------------+------+\n",
      "| 101 Server|             85|           80|     A|\n",
      "| 101 Server|             80|           90|     A|\n",
      "| 102 Server|             85|           40|     A|\n",
      "| 103 Server|             70|           80|     A|\n",
      "| 104 Server|             60|           80|     A|\n",
      "+-----------+---------------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM na_table WHERE na_col IS NOT NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
